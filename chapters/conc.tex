\chapter{Review and Conclusions} %3400
\label{ch:conc}
This thesis has in many ways been a journey; it has taken intellectual twists and turns as various approaches or philosophies have been explored, consumed and integrated; it has a clear beginning and end, both in terms of the written thesis and the course of study; finally it has been a means to meet an objective, personally and for the wider archaeological discipline.

\section{Review}
The study set out to evaluate current approaches to spatio-temporal analysis from both a methodological and theoretical stand point and to challenge an emphasis on the temporal dimension. This emphasis being a recent, potential over reaction to the spatial dominance that has existed for a considerable amount of time within archaeological analysis. To this end it has attempted to demonstrate how space and time may be recombined for fully integrated analysis of the available data, using a set of case studies at different scales. That such a bias exists is demonstrated by the prevalence of the two methods examined in the case studies, firstly bayesian modelling of dates and secondly summing radiocarbon probability distributions. These methods focus almost exclusively on the temporal side of the data, but their use is much more common than more spatio-temporal techniques such as aoristic analysis (e.g. \citealp{Crema2012,Crema20101118}) or the examination of land use patterns (e.g. \citealp{ARCM:ARCM578}). This is likely down to the less than inspiring results from such combined methods, compared to those from the purely temporal approaches. 

The first case study, on Hambledon Hill, demonstrates the potential for using a single value from a bayesian modelled date as a representation of the data set, to perform several forms of spatio-temporal analysis combined with a detailed qualitative review of the data. It showed the importance of not extracting the temporal evidence from its spatial context, how the spatial data can be used with the modelled dates to provide important information about the nature of the data set and that interpretations of the data are most productively made when considering both the temporal and spatial components of the data. The review of the data identified fundamental, implicit assumptions about the comparability of temporal data without considering the lack of spatial proximity. Specifically its contemporaneity, as dates from different parts of the site were combined in the model as though they were from samples of material found next to one another. There is clearly the potential that the routine application of such an assumption is likely to cause invalid results. A detailed review of the chronology can mitigate this to some degree, by assessing the likelihood the contexts the dates come from are the same, but it is also crucial that the spatial relationship between elements of a model is clearly identified so that the proximity between those elements is obvious. 

The study went on to examine different ways of performing spatio-temporal autocorrelation analysis, creating a successful approach that demonstrated a positive autocorrelation. This added weight to the evidence from the qualitative review, that dates with similar values occur relatively closely in space and (chronological) time. The result of this distribution of the data is that very few areas have models that span the full depth of the chronology, so for example in the main enclosure of Hambledon Hill segments five to seven have no dates beyond phase III, where as segment 17 has only dates from phase III. While sections have been excavated from around the enclosure, the evidence for particular sections of chronology tends to come from areas that are close together, which is then assumed to apply to other areas. In other words, for individual phases (and groups of phases) the evidence is more scarce than the proportion of the site that is excavated would imply, so the weight of interpretation is borne by less evidence than is immediately obvious. However this was not the case everywhere, the model of the central area is grouped by spatial sub-sections, in some cases with relatively deep chronologies. A fundamental problem is that this is not always clear, due to the presentation of the bayesian model, as any spatial (and stratigraphic) information is encoded in the headings of groupings. This results in a lack of consistency and a general absence of the information. 

In order to overcome this absence of information a selection of quantitative approaches were used as descriptive (rather than interpretative) methods on the data, these went from the coarse grained global Moran's i to the more fine grained, local measures. The local techniques highlighted those areas that would benefit most from further investigation, in this regard the techniques could prove useful for planning the allocation of resources should anyone attempt further investigation on the site. Finally the study re-visited the chronology of the site in light of the results of the quantitive methods and examination of the bayesian model, focusing on those areas where the evidence enables the most detailed interpretations. Fundamentally this study focused on the importance of having a detailed understanding of one's data set, both with regard to its temporal dimension and spatial dimension, using quantitative approaches to augment that understanding, and making sure the conclusions are supported by the evidence.

The second case study, focusing on the EUROEVOL data set, showed that there were fundamental problems to the summed probability distribution approach, which go beyond anything a combined spatio-temporal analysis could help to mitigate. This chapter demonstrated that instead, with such a large data set, it is important to use analytical techniques that are sympathetic to the nature of the data set (fragmentary, observational and biased), by the use of methods such as exploratory data analysis or simulation. The critique reviewed the potential problems with the SPD method, such as the need to apply a kernel density estimate to remove the artificial fluctuations caused by the calibration curve \citep{BROWN2015133}, issues around taphonomic loss, how it might be corrected for, the problems of using global correction and whether an exponential function for loss is valid \citep{SUROVELL20071868, SUROVELL20091715, Williams2012578, BALLENGER20111314}. Focusing on the theory behind the method, \citet{BALLENGER20111314, McLaughlin2016, Torfing2015193} analyse in detail the effects that research focus can have on biasing the distribution, from individual researchers, to the focus of research programmes, visibility of certain sites, and the bias of cultural resource management / developer led excavation. Also identified by \citet{McLaughlin2016,Torfing2015193} is the effect different types of sites can have on the record, as different types of sites have been investigated in varying proportions, but also reflect very different cultural behaviours.
 
The chapter went on to review two further fundamental aspects of the method, firstly, the large data set fallacy. \citet{Timpson2015199,Williams2012578} claim that with enough data the combined biases will approach a random error and therefore treat the data as a statistical sample. The ``law of large numbers'' they use is a heuristic, rather than one of several mathematical laws, which rely on unbiased samples and repeat observations under identical conditions. This is also a fundamental issue for archaeological data analysis more generally: can our biased, fragmentary observational data sets be treated as random samples for statistical purposes if they meet some condition? Or indeed can they ever be treated as such? The final criticism of the method was on the weight placed by \citet{Williams2012578} on significance testing of the null hypothesis, however the proposed null hypothesis is a false dichotomy and in no way enhances the link between summed probability distributions and population levels. It is also highly likely that components of the modern SPD approach have been designed based on a researchers familiarity with the data set, with potentially multiple, un-reported, analysis tried until a convincing result is achieved. 

This case study also demonstrates the value of modelling approaches, which have a long history at the centre of archaeological data analysis, as shown by \citet{doi:10.1177/0162243916671200} and which forms the basis of many current methods, such as bayesian modelling of dates. Here they are used as a form of EDA, with the data being used to determine the nature of the model, and the model results used as much to understand the nature of the data set as to create inferences about archaeological processes.

These studies were a means to demonstrate and explore the approaches to theories, methods and tools that were identified at the beginning of the thesis as a set of requirements for successful spatio-temporal analysis. They were phrased there as: asking the right questions, having appropriate methods and the availability of suitable software. It is now time to evaluate these components, in light of the case studies.

In terms of the questions asked from data, a fundamental influence came from \citet[51]{Evans:2006fk} to ``investigate ... questions beyond the descriptive''. This is clearly along the same vein as the ``persistent divide in archaeology between analytical and descriptive approaches ... if archaeology is to be more than mere catalogues of material then we need to go beyond them and address the factors accounting for variation in that material'' of \citet[200]{Timpson2015199}. However, they also, perhaps unfairly characterise proponents of the descriptive approach as being unwilling to infer anything without a complete knowledge of all the factors affecting the archaeological record. The view presented by \citet{Timpson2015199} is a subset of what \citet{Evans:2006fk} proposes (presented, as a false dichotomy with a straw man version of other aspects of the discipline). 

Using analytical approaches to account for variation in archaeological material is one way of going beyond description, another way would be to offer interpretation of the material and use that as evidence to infer the cause of variation. To go beyond merely describing temporal data it will be necessary to consider what \citet{Lucas:2005fk} describes as the temporal structure of activities, as it is these activities which will be reflected in the temporal data. These are activities where people engage with the past, or future, no matter how small or large the time scale. One might argue that this is all activities, however such temporal structure is not always routinely considered and the spatio-temporal even less so. Some potential approaches were examined, notably: the time-consciousness of past societies or cultures, the temporality of such societies, questions of social memory, of the continuity of cultural practice over time \citep{Lucas:2005fk}. \citet{Bradley:2002fk} focused on time as an essential part of society, of people dealing with their cultural past, both near and far, considering the future and encountering remains from the earlier past. This has parallels with the palimpsest of meaning of \citet{Bailey:2007fk} although that is perhaps closer to the biographies of \citet{10.2307/125007}. All these approaches offer an interpretational optimism, although \citet{Bailey:2007fk} does warn of the problem of chronological indistinguishability, a lack of resolution in the data. Chapter two offered some possible questions, for Hambledon these were to do with how the activities on site changed or not over time; whether activity focused on different areas of the site over time; evidence for re-interpretation of the site due to the infrequency of use \citep[755]{Mercer:2008fk}. There is also the suggestion that construction of part of the site followed a long term plan \citep[760]{Mercer:2008fk}. For the EUROEVOL data set, possible questions were around the relationship between regional and local phenomena and the potential for notions of past in the past to be represented at the larger scale.

The spatio-temporal analysis of Hambledon Hill touched upon these questions, albeit less explicitly.  The re-analysis of those parts of the site with the greatest spatio-temporal evidence provided the best opportunity for answering such questions, for example segment 17 of the central area is a clear example of how the activities undertaken at that part of the site changed over only a relatively short period of time and also potentially an example of re-interpretation. Notably the ditch went from a significant feature to no more than a shallow depression potentially over a period of less than a couple of hundred years. The cultural memory of a very different site may well still have been in circulation during the final decades of it silting up. The final phases of use show a very different pattern to the first dumps on the ditch bottom, in particular the burial cut into the side of a causeway, right at the end of its Neolithic sequence. The ditch is no longer a physical boundary, it might have simply been the easiest place to dig, but more likely it was a known location10.2307/125007 as the burial only took place between 15 and 150 years after the previous deposits. While this is only evidence from a small part of the site, it is a glimpse through the keyhole, which can help address questions about the changing way Hambledon was used and experienced. At the time the ditch was no more than a shallow depression the site was still subject to intense activity elsewhere, the ditch likely was the subject of folklore or myth as a means of explaining it's existence, a feature in the landscape in many ways taken as a permanent fixture, but one also surrounded by cultural interpretation.

The shifting focus of activity is also well documented on Hambledon, starting off at the central area, before moving out to the Shroton spur and then the Stepleton enclosure. While it is difficult to be specific about how much time elapsed before the focus of activity shifted, the chronology of the site is clearly demonstrated in the bayesian model from figure~\ref{fig:period-model}. The fundamental question for the Hambledon case study, was the same as that for this thesis, that of the benefits of combined spatio-temporal analysis. In answering the kinds of questions posed above, the benefits of this form of analysis are clearly demonstrated.  The significant contribution of this chapter then, to the chicken and egg situation of spatio-temporal analysis \citep{Bailey:2007fk} is the contribution of a methodological approach to answer such questions. It shows that archaeologists should not be afraid to start with issues of temporal interpretation or analysis, building on the work here to adapt and improve a combined quantitative and qualitative analysis of spatio-temporal data. The analysis of the Hambledon data has also brought into focus another valuable form of spatio-temporal analysis, that of the data set itself, showing that temporal analysis need not exclusively answer temporal questions. By exploring the shape, or make up of the data set, in this case the spatio-temporal auto correlation, it is possible to focus our attention on those parts of it which are most valuable and modulate our conclusions so that they are supported by the data. Finally an understanding of the data set can be used to clearly demonstrate those areas that would benefit most from further investigation.

The analysis of the EUROEVOL data set took the same fundamental question of the benefits of spatio-temporal analysis to a much larger data set, on a regional scale. At this scale the chronological indistinguishability, particularly of radiocarbon dates, with their often large distributions, becomes an obstacle to answering questions of past in the past. Bayesian modelling is not applicable over such large scales and while it would be possible to create local models for each site, that would take a considerable amount of time. The value of such a data set is then, not in its chronological resolution, but in it's scale and spatio-temporal spread. The data set is a collection of many independently gathered data sets and so it is even more valuable to ask questions about the make up of the data. Having a detailed understanding of its composition is crucial to determine whether it is valid to use certain analytical methods with the data set. The clear gaps in the data set and unexpectedly late dates for Neolithic transfer into some cells demonstrated the partial coverage both in terms of space and time of the data set. The clear concentrations of these artefacts in the data show that any technique that relies on a statistical sample, or assumes repeat observations under identical conditions cannot be reliably used with the EUROEVOL data set. The simulation has shown that while a relatively simplistic cellular automata model can be used to model the data set in part, the lack of comparability for the entire duration indicates that the transmission of Neolithic culture and practises was a much more nuanced process. Some areas, such as northern France and the British Isles deviate significantly and would appear to be governed by an entirely different process to central Europe, although this is not a new observation \citep{gkiasta2003neolithic}. It is clear that there are more challenges to answering questions on the temporal structure of activities with a large, lower resolution data set, but it is still a potentially fruitful endeavour provided suitable methods are chosen.

The concern for appropriate analytical methods was the second pre-requisite identified at the start of this thesis. Chapter three reviewed a range of applicable methodological schools, starting with spatial analysis, to temporal analysis and then combined spatio-temporal methods. Some fundamental concerns were identified, primarily from reviewing the more mature field of spatial analysis, such as the problem of using culturally specific representations, the applicability of methods to the questions asked of them, a concern for the theoretical foundations of a tool or method and ultimately how to bridge the gap between method and theory. More specifically the review of bayesian dating found that issues existed with the application of the method e.g. \citet{doi:10.1080/00438243.2015.1070082}. However, provided best practices are followed (e.g. \citealp{doi:10.1080/00438243.2015.1067640}) and key pitfalls avoided, for example by being sure of the relationship between dated and modelled event, ensuring only reliable priors are included, making sure there are a sufficient number of dates and a critical examination of results, the technique is fundamentally a valuable contribution to the field. This contrasts to the main reviews of summed probability distribution approaches of \citet{CAJ:676108,Torfing2015193,McLaughlin2016} which argue that it fundamentally come down to a naive view that each date is an independent event. As was demonstrated in the analysis of Hambledon Hill, there is often a strong spatio-temporal auto-correlation in radiocarbon data sets on archaeological sites, a trait that is unlikely between independent events. This is also clearly present in larger data sets, caused by the influences on the data examined by \citet{Torfing2015193}. This study has shown that potential gaps in the data set can be located using exploratory data analysis. 

For the analysis of Hambledon Hill a qualitative analysis of the dates and chronology was undertaken first, which came to a conclusion that spatio-temporal autocorrelation was likely to be present and also identified the areas on the site where the data set was of a higher and of a lower quality. The quantitative analysis that followed broadly replicated these results, more specifically the identification of autocorrelation in the data was confirmed, across the whole data set. Specific areas of potential interpretative worth, due to clusters of dates, were located by the local methods, which also identified those areas that could most benefit from further dating evidence. The benefit of performing a review of the dating evidence independently to the analytical method is the corroboration of the results it provides, regardless of the abstraction to the date values required. The same is not true for the EDA and model using the EUROEVOL data set, primarily due to the size of the data set, making it unfeasible to perform such an analysis date by date. However for corroboration there is also the entirely independent analysis on a similar (although smaller) data set of \citet{gkiasta2003neolithic}, which obtained similar results using a range of methods.

In chapter three the importance of bridging method and theory is referenced, for the Hambledon study the gap was bridged by contextual interpretation. The results from the quantitative analysis were compared and contrasted to that of a thorough qualitative analysis of the data set. Interpretations were presented based on the results of these, contextualised with additional details from \citet{Mercer:2008fk} and where the data was of sufficient detail, questions of continuity and re-interpretation of the past were considered. As discussed previously, such interpretations are much more difficult with the EUROEVOL data set, due to it's chronological resolution, but also the lack of contextual archaeological information. Instead the interpretations here were more around potential issues with the data set, although the lack of interpretative theory for working with such large scale data sets, presents a clear and interesting opportunity for further work.

The application of chosen methods requires suitable software. Chapter four reviewed existing spatio-temporal software, current temporal GIS were shown to be lacking in capability. The essential components of temporal GIS were reviewed in order to understand the requirements that a bespoke system would require to conduct spatio-temporal analysis. For Hambledon no custom software was required, this was because only a single value was used for each date, which meant that existing tools within ArcGIS were usable. For the EUROEVOL data set a suite of custom tools was built to facilitate the EDA approach. \citet{doug_cowie_2018_1297321} provides two key capabilities, firstly it extracts the mean value for each date from the raw OxCal output and secondly, it identifies the earliest data classified as Neolithic for each cell. These capabilities enable the large EUROEVOL data set to be abstracted to a single value per date, just as for Hambledon, so that standard analysis and visualisation tools can be used. The benefits this provides is a simpler data set to handle, a wider range of statistical methods to choose from and straightforward computation of analytical procedures. The drawbacks are a fundamental loss of the data, the false precision and ultimately that the chosen value is unlikely to be the actual date of the material. These problems are exacerbated when the distributions are large and minimised for the bayesian modelled dates, as these have much smaller, tighter distributions. In addition the cellular automata model, \citet{doug_cowie_2018_1297319} was developed specifically for the EUROEVOL case study. Its behaviour was reviewed during the case study, so shall not be repeated here.

A fundamental limitation through both case studies has been the lack of data, specifically a broad spatial spread through a deep chronology. The greater the coverage of the data set, the more useful the applied techniques would become and a greater weight could be placed on the inferences developed due to their results. As this is unlikely to happen, due to the scarcity of datable material from the Neolithic, resource constraints on how much material can be dated, and the necessity that each dates context be secure, it is crucial we make best use of the material we have available. The fundamental argument of this thesis is that this is best accomplished by considering both spatial and temporal components of our data together. While the methods used are clearly open to improvements, the results nevertheless demonstrate the value of combined analysis.

This thesis set out to review and enhance the subject of archaeological spatio-temporal analysis, specifically through the use of case studies at multiple scales to demonstrate the benefits of combined spatio-temporal analysis. In this it has been successful. These two studies demonstrate methods for working with archaeological data at both ends of the scale of data set size. In one case by augmenting existing methods, in the other by suggesting alternative approaches. They both show the importance and value of considering the data in it's archaeological context and in considering the nature of the data itself. The importance of considering what could be termed the `shape' of a dataset, its gaps and clusters, correlations and auto-correlations can be used to examine potential biases and crucially can show which parts are more or less reliable for supporting our inferences. When these prerequisites are met and the data is analysed sympathetically to its fragmentary and biased nature the case studies show how it can be used to answer some of the most interesting questions.

\section{Conclusions}
The case studies presented demonstrated different forms of spatio-temporal analysis for working with data at different scales. The difference between these scales of data is not just in the size of the data set and the applicable methods, but also the intellectual tradition. The highly contextual approach undertaken for Hambledon, following that of \citet{Whittle:2011kl} (among others) focuses on detailed comprehension and consideration of as many of the processes affecting the data as possible. This is in contrast to the analysis of large data sets, the SPD method is typical of the generalising, reductionist approaches used for such large data sets, a key example being \citet{Shennan:2013fk}. These two different scales highlight the different approaches of the neo-processualists and the post-modernists (or subject centred archaeologists to exclude some of the more extremes of that tradition). There is little exchange of ideas between the two camps. On the rare occasion ideas are taken from one side and applied to the other, for example \citet{Torfing2015193} they are often met with scepticism and criticism, such as \citet{Timpson2015199}. Clearly both sides have important points to make, this thesis has demonstrated the importance of having detailed knowledge of one's data set, however there must be a limit to this as a pre-requisite for analysis, we should not start to think that ``unless we have complete knowledge of all the factors that might possibly affect the record available to us, which of course we never will, then we cannot say anything at all'' \citep[200]{Timpson2015199}. 

By taking a diverse set of case studies this thesis has bridged the divide, both in terms of scale of data set and of intellectual tradition. Both case studies demonstrated how broad, generalising statistical methods could provide descriptive information about a data set, requiring a contextualised review to fully appreciate the significance of the results. Examples of this from Hambledon are perhaps easier to identify, such as segment 17 from the central area, however there were still several examples of areas of the EUROEVOL data set that would benefit from further investigation, such as the spread of the Neolithic to Britain, the lack of data in central France and in central Germany. This shows that there is a place and a benefit for broad, generalising methods, regardless of the scale of analysis. It also demonstrates the importance of understanding the nature of a data set, that simply increasing the size of a dataset is not a valid substitute for contextual knowledge. It may never be possible to have complete knowledge, it is crucial to attempt to pragmatically include that knowledge which is pertinent to the conclusions being drawn. While it is unlikely that both intellectual traditions can be unified, it is crucial to acknowledge that the association with a scale of data set is loose and certain scales do not presuppose specific ways of working with data. It is also important that archaeologists have ways of working with data sets (especially large ones) where there are many unknowns around factors affecting the archaeological record and that data is evaluated contextually.

From a broader perspective it is important to note that such methods are rarely used in isolation. The methods presented here have in a sense been deliberately simplified, focusing on the spatio-temporal data. This is artificial as there is often so much more information available for interpretation and analysis that can be combined for a more thorough understanding of the past. Such multi-faceted analysis is essential to alleviate common concerns the methods presented here have also been guilty of and which our discipline has perennial struggles with, such as using modern maps, showing the geography as it is now, rather than during the time under consideration. With modern maps being a facet of our culture, not those under examination, their spatio-temporal understanding and mental (or physical) representations are likely to have been different. In a similar way bayesian modelling clearly presupposes the primacy of the modern temporal structures of radiocarbon dates on a BP scale and relative chronology. It is also clearly not a theoretically neutral tool, as the model represented in the prior is an act of interpretation and the results focus on phase boundaries, durations and gaps between phases, rather than the more lived in time of \citet{Lucas:2005fk} and so must not be ascribed a sense of objectivity. 

The entirely a-spatial nature of bayesian models clearly supposes that the dates are all spatially compatible, in fact there is no spatial consideration with the technique at all, the model is one dimensional, the only dimension being chronology. Dates from samples found next to each other may be treated the same as those found on opposite parts of the site. This is why it is important that as bayesian modelling of radiocarbon dates becomes more mainstream within the discipline the spatial context of those dates is not divorced from the model. The place of such modelling in smaller scale studies is well established, with volumes such as \citet{Whittle:2011kl,Whittle:2011tg} expanding this up to regional scales of analysis. Such studies demonstrate the value of this contextual and descriptive analysis over larger scales and considering large scale questions, such as the nature of the early Neolithic in Britain and Ireland and how it spread across those islands. This leads to the question of the place of bayesian modelling in even larger, continental scale studies. It would take a tremendous amount of work to undertake on a European scale, but maybe that is what is required to take our understanding of the spread of Neolithic culture and practices across Europe to the next level. One form of payoff is that this would enable narratives and descriptive interpretations at a much larger scale, but the data generated would also enable even more forms of generalising analysis using the new data set. Such an outcome should not be seen as the preeminence of one tradition over another as there will always be the generation of ever larger data sets that required reductionist methods in order that it is computationally feasible to say something about them at all.

The expansion of bayesian modelling to larger data sets should not be seen as replacing many of the methods currently employed. Techniques such as modelling and EDA will continue to have an important place, as they do with much smaller set. What is essential is that such techniques are thoroughly analysed and critiqued, for example consider the basis of the EDA undertaken on the EUROEVOL data set. It suffers similar criticisms to the bayesian approach, in that modern temporal representations are favoured. In defence of this there are no viable alternatives for the study of the European Neolithic, it is more down to a focus on abstract or relative dates, or a combination of the two as in bayesian modelling. The EDA method chose to apply an arbitrary grid for ease of representing the data, as a reason this may be theoretically neutral, but the act of carving the study area up so arbitrarily potentially risks masking patterns in the data, that a more culturally sensitive division of space might have amplified. The difficulty is of course in determining how to perform such a division, looking for clusters in the data is a potential option, although this is equally likely to determine clusters due to post-depositional processes or recovery biases. The cellular automata makes many of these theoretical assumptions explicit, such as, that the Neolithic was transmitted through space and time, via a process that at the level of a population is not dissimilar from the transmission of communicable diseases. 

Taking a step back, this thesis has touched upon several topics that have considerable relevance to the wider discipline. The method of summed probability distribution has become a controversial topic with polarised opinions and with careers or at least projects, depending upon it. Some have sought to frame it as a re-ignition of previous debates about the scientific method, hypothesis testing  and quantitative methods, such as the ``persistent divide in archaeology between analytical and descriptive approaches'' \citep[200]{Timpson2015199}. It is no such thing. The general acceptance and use of bayesian methods shows that archaeology as a discipline is more than comfortable with quantitative methods at a range of scales, the creating and comparison of multiple bayesian models, demonstrates how au fait we are at testing hypothesis mathematically. Fundamentally the scientific method is alive and well within archaeology, the disabuse of summed probability distributions for determining population levels does not conflate to a disabusement of the scientific method as a whole. 

Of particular relevance from the analysis of the SPD method is the temptation with such a large spatio-temporal data set to treat it as a statistical sample, which is not necessarily appropriate. To make the most of the available data it is important to consider both it's spatiality and its temporality, a complicated operation when the temporality takes the form of radiocarbon dates. However approximations can be used to enable analysis and representation and the data may be grouped to further aid display. Such abstractions, while taking away some of the detail of the data, does make the kind of exploratory data analysis used a viable option for doing more than simply creating ``catalogues of material'' \citep[200]{Timpson2015199}. 

For the wider discipline this thesis has shown the importance of quantitive techniques, in particular combined spatio-temporal methods. It demonstrates that bayesian modelling should be more spatially aware in future and that this need not be a limitation to the interpretations that can be offered. It has also shown that the method of summed probability distributions is ineffectual, but that there are many potential options to replace this with as a form of quantitative analysis for large scale data sets. From an even wider perspective it has shown the usefulness of analytical techniques for analysing the make up of a data set, at both the scale of a site and a continent. Such analysis is important due to the limited knowledge we have of the processes that generated a data set. It can be used to tease out the effects of such processes and is essential in making sure that conclusions are appropriate for the limitations of the data set.

There are several areas with more specific relevance to certain current trends of archaeological analysis. In particular the growing avenue of ancient DNA analysis, such as \citet{Skoglund466} that is attempting to overturn the status quo on the spread of farming, that it was as much down to the spread of ideas as that of people, with regional variation between the significance of the two processes. Genetic studies are broadly (although not all, e.g. \citealp{Haak1016}) demonstrating the importance of the spread of populations. However, there are concerning characteristics with such studies, some that are familiar from the analysis of SPD approaches. First the sample sizes are often incredibly small, \citet{Skoglund466} draws on evidence from four individuals, this is clearly far too small to derive conclusions such as ``the genetic composition of contemporary Europeans may have been shaped by prehistoric migration that drove the expansion of agriculture'' \citep[469]{Skoglund466}. \citet{Olalde:2018fk} sets a high standard in this regard, although for studying the Beaker spread into Britain this is still less than 200 individuals, only a fraction of the prehistoric population. Despite the low number there is little description of the data set, for example spatial distribution or the different type funerary context or tradition of each individual. There are then the same kinds of biases as those identified by \citet{Torfing2015193} that are systematic throughout the data set, meaning it cannot be treated as a random sample. In the case of these studies, the individuals whose DNA has been sampled are those who are more likely to have been excavated, likely coming from a more obvious burial or funerary monument. It is entirely possible that those who moved around were ascribed a certain status in life and in death, but due to this they are more likely to have been sampled by modern archaeologists. Also there is the concern of this thesis, that such analysis very often lacks a spatial dimension, with such small samples this is perhaps less useful, but it is clearly worth considering the spatial distribution of migrant individuals.

Another area where this thesis has direct relevance is the creation of archaeological models. Cellular automata is a relatively simple form of simulation, much more detailed modelling strategies exist that could also be used to explore the data set. Cellular automata was chosen due to it's simplicity as a more detailed simulation that accounted for taphonomic processes and investigation biases would be much more involved, and because we do not have a clear idea of how these processes would have affected the original distribution at a local (or even regional) level across the study area. At a high level of abstraction this would leave three process to include in the model, the pattern of deposition, pattern of taphonomic loss and the pattern of recovery, with each of these being a potentially complex collection of smaller processes. Creating a simulation to account for these, even at a high level of abstraction is not a simple operation, and without an independent data set to verify the model against, it is effectively an exercise in gazing into a crystal ball. Even with such a data set, to attempt to verify the model it would be necessary to have a sufficient understanding of at least one, ideally two of the processes so that their effects on the data set could be isolated. In reality this is unlikely to be exact, but enough that the effect of the modelled behaviours is clear. Another method of validating a model is the null hypothesis test, in this case the modelled behaviour becomes the null hypothesis, with the actual data set being tested against the model output. Using this method, the options become a dichotomy, the potential for more descriptive analysis with model creation is quickly replaced with the single analytical result of a significance test. Such a test requires the modelled processes output to be combined into a single set of results for comparison, removing any indication of the effects of the individual processes. Performing independent null hypothesis tests for each of the modelled processes would be preferred, but this would require extracting data for each process from the data set. Without a detailed understanding of each process, this would likely result in an exercise of data laundering as the assumptions being tested by the null hypothesis would be the same as those used to extract and manipulate the original data set to draw out the effects of a particular process.

The final area with specific relevance is that which makes up the core of this study, spatio-temporal methods. The aoristic methods of \citet{Johnson:2004fk,Crema20101118} share similar problems to the summed probability distribution approach, in that they are mathematically heavy and archaeologically light. The lack of integration or consideration of the archaeological context of the data is a clear limitation, and just as with the SPD approach the results have very little inherent meaning. The modelling approach of \citet{Demjn2016100} presents an interesting avenue of research, the creation of spatio-temporal simulations is in some ways limited, although clearly all simulations have a temporal component, few are used to simulate temporal data. Unfortunately that study was based on limiting assumptions about the spatial size and shape of archaeological sites, that archaeological sites have a half life. It assumeed cultural behaviour is static and it does not account for post depositional process that may affect the archaeological record the modelled results are compared to. The other tradition of spatio-temporal methods is that coming from research into archaeological Temporal-GIS, the first such system was \citet{Johnson:1999cr} however that was only able to cope with absolute dates, making it effectively useless for much archaeological work, which relies on probabilistic dates. The only other attempt was that of \citet{Green:2008fk}, who created a system capable of storing and analysing archaeological temporal data with an existing GIS package. His system ultimately calculated the probability that a spatial feature, with an associated date value fell within a specified time interval. The system had two fundamental limitations, primarily the only form of analysis he was able to perform with it's outputs was to interpolate the probability values spatially for each specified time window, and secondly that his results were always presented with a static back drop, so the relevant archaeological contextual information was not shown along side the results. It is highly likely that his interpolation would have suffered from the kinds of spatio-temporal auto-correlation identified at Hambledon. If this is the result of post-depositional processes it would have the potential to question the validity of his results showing how different parts of a site had more or less focus over time. By contrast, the techniques demonstrated here, rather than attempting to plumb the spatio-temporal data set for hidden meaning, have focused on identifying characteristics of its distribution, to be included in the chain of inference behind the archaeological arguments.

So, where does this leave the future of archaeological temporal-GIS? Fundamentally there is a lack of people asking temporal questions, specifically questions where there is an appropriate method that can work with the primary temporal data formats of radiocarbon dates and chronology to generate results. There is a lack of questions being asked that can bridge the gap between method and theory to be used to infer details about the temporal structure of past activities. The key gap is clearly on the method side, as multiple temporal theoretical approaches exist, however the fragmentary nature of the archaeological record does mean that bridging the gap between method and theory will always be difficult and likely only possible on parts of sites that have a good coverage of reliable dates to be used in analysis. The relative complexity of performing statistical operations on radiocarbon dates means that it is simply not possible to adapt methods for working with point representations of time. It is this lack of available methods that has led researchers to the relative complexity of aoristic analysis and summing probability distributions but as has been noted such techniques de-contextualise the archaeological data, rendering the results distant orphans from the context that gave them original meaning. A clear path to the light through these murky waters is a focus on exploratory data analysis, while the available methodology is small, it offers the potential to put spatio-temporal data sets of varying sizes to use and is a process by which valuable methods may be discovered and additional avenues of research opened up.

The need for such tools and methods will only accelerate as the quantity of samples sent for radiocarbon dating increases and the uncertainty in such dates decreases with bayesian modelling. The increasing availability of data and technical challenges of working with such large data sets makes the allure of big data techniques appealing, but this thesis demonstrates that caution is essential when analysing these kinds of approaches, due to the fragmentary, biased nature of the data. Often they are statistically simplistic \citep[8]{donoho201550} and make assumptions about the data set distribution that are often not met. Working on the unfounded premise that more is better, such approaches often fail (or are unable) to consider the source of the data, the processes that have shaped it. Clearly this compares unfavourable to methods available for relatively small data sets, which are often much more specific and are able to consider the archaeological context of the data. 

Ultimately performing spatio-temporal analysis of archaeological data, in particular radiocarbon dates is a non-trivial activity. There are a range of theoretical problems and identifying interesting questions to ask is not always straightforward. To compound this are the methodological complexities of performing traditional analysis on the probability distributions that make up radiocarbon dates and the availability of techniques that can work natively with such data. This is why the discipline has moved so little since \citet{Castleford:1992fk} over 25 years ago. It is for this reason that it is imperative that the tradition of contextualised analysis is continued in the domain of temporal analysis, so that the discipline is appropriately tooled and skilled to deal with larger and larger sets of spatio-temporal data. We are still a long way from archaeological temporal GIS, but are developing a growing corpus of spatio-temporal analytical techniques, which one day will lead to a platform for such analysis.